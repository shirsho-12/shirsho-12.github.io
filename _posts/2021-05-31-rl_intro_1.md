---
layout: post
title:  Reinforcement Learning - An Introduction
subtitle: RL Basics
permalink: /blog/rl_1/
tags: [Reinforcement Learning, RL Basics]
comments: true
---

* * *

According to Wikipedia, _Reinforcement learning (RL) is an area of machine learning concerned with how intelligent agents ought to take actions in an environment in order to maximize the notion of cumulative reward._<sup>[1](#myfootnote1)</sup> . This sentence both says a lot, and at the same time tells very little. In laymen's terms, reinforcement learning is teaching a worker (the agent) to learn how to perform a task on its own. But how does an agent learn on its own? We leave the agent to its own devices. The agent is free to take whatever allowed action it wants and over time it may stumble onto a solution. We incentivize good solutions by giving the agent a task: maximize reward. This reward is specified by the programmer (a.k.a. us). Oftentimes we reward the agent for coming to a solution and apply penalties to longer solutions to encourage good solutions. 

Let's first set out a few definitions:
- **Agent**: The entity that is taking actions. In this case the agent is our algorithm that is trying to learn the optimal solution. A real world example would be a chess player.
- **Environment**: The world the agent interacts with and is not in complete control over. The agent's environment may not only be its outside world. For example, a robot dog's environment not only consists of its surroundings, but also of its battery. After all, if our robot dog went outside in the yard and its battery died right before a snowstorm, it would be rather inconvenient.
- **State**: The current condition of the environment.
- **Policy**: The way an agent behaves in a certain time/position. In a more mathematical sense this is the mapping from the perceived state(what the agent sees) to an appropriate action.
- **Reward**: This is the value we aim to maximize in the reinforcement learning problem. It is a measure of the *immediate* desirability of a state.

<img src="/images/rl/Spot_the_dog.jpg" desc="Spot the Dog" caption="CAImagine your brand-new $74,500 Boston Dynamics robot dog Spot failed to keep its battery level in mind and got wasted in a blizzard. Tragic!">
<!-- {% include image.html url="/images/rl/Spot_the_dog.jpg" description="Imagine your brand-new $74,500 Boston Dynamics robot dog Spot failed to keep its battery level in mind and got wasted in a blizzard. Tragic!" %} -->

<!-- ![]() **Image Caption Formatting Needed** -->

A simple example would be that of a chess position. The players are the agents, the chess board the environment and the reward victory. A move is an action, and the resulting chess position the state after move *t*. 

It should be noted that we are only rewarding final outcomes. We rarely, if ever, evaluate intermediate states/positions on our own, this is for the agent to figure out. This is primarily because human evaluations are often inaccurate. Give 10 people a difficult chess position and they may have wildly varying opinions on what's best to do. We let the agent determine the desiribility of a state in terms of its long term prospects, i.e. its **value**. 

Strictly speaking, values are predictions of future rewards. It is these values the agent continuously estimates, evaluates and re-evaluations. For the best course of action, the agent picks the actions with the best values in what we call a *greedy* manner.

To summarize, the key feature of a reinforcement learning algorithm is its ability to interact with the environment, take feedback from it, and learn. Like a toddler learning how to walk, the algorithm/agent continuously tries different actions until it finds the best/most rewarding one.


## A Chess Game

Let's start a game of chess. Two players take turns to on an <img src="https://render.githubusercontent.com/render/math?math=8\times 8"> board, each moving one of 16 possible possible pieces.

<a name="myfootnote1">[1]</a> Hu, J.; Niu, H.; Carrasco, J.; Lennox, B.; Arvin, F. (2020). ["Voronoi-Based Multi-Robot Autonomous Exploration in Unknown Environments via Deep Reinforcement Learning"](https://ieeexplore.ieee.org/abstract/document/9244647). IEEE Transactions on Vehicular Technology. 69 (12): 14413-14423.








